{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, time, datetime\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from common.dataset import TrainDataProvider\n",
    "from common.function import init_embedding\n",
    "from common.models import Encoder, Decoder, Discriminator, Generator\n",
    "from common.utils import denorm_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Mindset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 문제상황\n",
    "1. 이전의 실험에서 learning rate 때문인지, 무슨이유인지 몰라도 mode collapsing이 발생함\n",
    "\n",
    "\n",
    "2. 각 폰트가 각자의 label에 맞지 않게 학습이 되는 것으로 보임\n",
    "\n",
    "\n",
    "### 수정사항\n",
    "1. 일단은 learning rate를 다시 잡아가면서 학습시켜보기로 함\n",
    "\n",
    "\n",
    "2. 그리고 데이터를 모든 폰트별로 11712자를 전부 학습시킬 필요는 없는 것 같고, 그 중 `2000자만 랜덤`으로 뽑아서 사용하도록 하겠음\n",
    "\n",
    "\n",
    "3. 또, `batch_size=16`으로 줄여서 학습하기\n",
    "\n",
    "### 다시 시작하는 지점\n",
    "1. 이전에 lr=0.001로 학습시켰던 모델 중 epoch 11까지 학습된 모델에서 다시 시작\n",
    "\n",
    "\n",
    "2. 그 이후, `20epoch`까지 lr=0.0005로, 30epoch까지 lr=0.00025로 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 다시 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import pickle as pickle\n",
    "import random\n",
    "\n",
    "\n",
    "def pickle_examples(from_dir, train_path, val_path, train_val_split=0.2):\n",
    "    \"\"\"\n",
    "    Compile a list of examples into pickled format, so during\n",
    "    the training, all io will happen in memory\n",
    "    \"\"\"\n",
    "    paths = glob.glob(os.path.join(from_dir, \"*.png\"))\n",
    "    with open(train_path, 'wb') as ft:\n",
    "        with open(val_path, 'wb') as fv:\n",
    "            print('all data num:', len(paths))\n",
    "            c = 1\n",
    "            val_count = 0\n",
    "            train_count = 0\n",
    "            for p in paths:\n",
    "                c += 1\n",
    "                label = int(os.path.basename(p).split(\"_\")[0])\n",
    "                with open(p, 'rb') as f:\n",
    "                    img_bytes = f.read()\n",
    "                    example = (label, img_bytes)\n",
    "                    r = random.random()\n",
    "                    if r < train_val_split:\n",
    "                        pickle.dump(example, fv)\n",
    "                        val_count += 1\n",
    "                        if val_count % 10000 == 0:\n",
    "                            print(\"%d imgs saved in val.obj\" % val_count)\n",
    "                    else:\n",
    "                        pickle.dump(example, ft)\n",
    "                        train_count += 1\n",
    "                        if train_count % 10000 == 0:\n",
    "                            print(\"%d imgs saved in train.obj\" % train_count)\n",
    "            print(\"%d imgs saved in val.obj, end\" % val_count)\n",
    "            print(\"%d imgs saved in train.obj, end\" % train_count)\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 75000개 수준의 dataset으로 작게 만들어서 다시 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all data num: 226659\n",
      "10000 imgs saved in val.obj\n",
      "20000 imgs saved in val.obj\n",
      "10000 imgs saved in train.obj\n",
      "30000 imgs saved in val.obj\n",
      "40000 imgs saved in val.obj\n",
      "20000 imgs saved in train.obj\n",
      "50000 imgs saved in val.obj\n",
      "60000 imgs saved in val.obj\n",
      "30000 imgs saved in train.obj\n",
      "70000 imgs saved in val.obj\n",
      "80000 imgs saved in val.obj\n",
      "40000 imgs saved in train.obj\n",
      "90000 imgs saved in val.obj\n",
      "100000 imgs saved in val.obj\n",
      "50000 imgs saved in train.obj\n",
      "110000 imgs saved in val.obj\n",
      "120000 imgs saved in val.obj\n",
      "60000 imgs saved in train.obj\n",
      "130000 imgs saved in val.obj\n",
      "140000 imgs saved in val.obj\n",
      "70000 imgs saved in train.obj\n",
      "150000 imgs saved in val.obj\n",
      "151911 imgs saved in val.obj, end\n",
      "74748 imgs saved in train.obj, end\n"
     ]
    }
   ],
   "source": [
    "from_dir = './get_data/hangul-dataset-11172/'\n",
    "save_dir = './dataset/'\n",
    "train_path = os.path.join(save_dir, \"train.obj\")\n",
    "val_path = os.path.join(save_dir, \"val.obj\")\n",
    "\n",
    "pickle_examples(from_dir, train_path=train_path, val_path=val_path, train_val_split=1-0.33) # 75000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> training dataset : `74748`\n",
    "\n",
    "- dataset spec: `25fonts`, `3000chars /fonts`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './dataset/'\n",
    "model_dir = './model_save/'\n",
    "fixed_dir = './fixed_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fixed Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1, 1, 128])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = torch.load(os.path.join(fixed_dir, 'EMBEDDINGS.pkl'))\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Fixed sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed sources: 26\n",
      "fixed targets: 26\n",
      "fixed labels: 26\n"
     ]
    }
   ],
   "source": [
    "fixed_sources, fixed_targets, fixed_labels = [], [], []\n",
    "\n",
    "# font별 fixed target\n",
    "for i in range(25):\n",
    "    source = torch.load(os.path.join(fixed_dir, 'fixed_source_%d.pkl' % i))\n",
    "    target = torch.load(os.path.join(fixed_dir, 'fixed_target_%d.pkl' % i))\n",
    "    label = torch.load(os.path.join(fixed_dir, 'fixed_label_%d.pkl' % i))\n",
    "    fixed_sources.append(source)\n",
    "    fixed_targets.append(target)\n",
    "    fixed_labels.append(label)\n",
    "    \n",
    "# 모든 폰트가 섞여있는 target\n",
    "source = torch.load(os.path.join(fixed_dir, 'fixed_source_all.pkl'))\n",
    "target = torch.load(os.path.join(fixed_dir, 'fixed_target_all.pkl'))\n",
    "label = torch.load(os.path.join(fixed_dir, 'fixed_label_all.pkl'))\n",
    "fixed_sources.append(source)\n",
    "fixed_targets.append(target)\n",
    "fixed_labels.append(label)\n",
    "\n",
    "print(\"fixed sources:\", len(fixed_sources))\n",
    "print(\"fixed targets:\", len(fixed_targets))\n",
    "print(\"fixed labels:\", len(fixed_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fixed_source는 일단 폰트 다 섞여있는 걸로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_source = fixed_sources[-1]\n",
    "fixed_target = fixed_targets[-1]\n",
    "fixed_label = fixed_labels[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper Parameter Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- batch_size 16으로 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONTS_NUM = 25\n",
    "EMBEDDING_NUM = 100\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = 128\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unpickled total 74748 examples\n",
      "unpickled total 151911 examples\n",
      "train examples -> 74748, val examples -> 151911\n",
      "total batches: 4672\n"
     ]
    }
   ],
   "source": [
    "data_provider = TrainDataProvider(data_dir)\n",
    "total_batches = data_provider.compute_total_batch_num(BATCH_SIZE)\n",
    "print(\"total batches:\", total_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(max_epoch, schedule, data_dir, save_path, to_model_path, lr=0.001, \\\n",
    "          log_step=100, sample_step=350, fine_tune=False, flip_labels=False, \\\n",
    "          restore=None, from_model_path=False, GPU=True):\n",
    "    \n",
    "    # Fine Tuning coefficient\n",
    "    if not fine_tune:\n",
    "        L1_penalty, Lconst_penalty = 100, 15\n",
    "    else:\n",
    "        L1_penalty, Lconst_penalty = 500, 1000\n",
    "\n",
    "    # Get Models\n",
    "    En = Encoder()\n",
    "    De = Decoder()\n",
    "    D = Discriminator(category_num=FONTS_NUM)\n",
    "    if GPU:\n",
    "        En.cuda()\n",
    "        De.cuda()\n",
    "        D.cuda()\n",
    "    \n",
    "    # Use pre-trained Model\n",
    "    # restore에 [encoder_path, decoder_path, discriminator_path] 형태로 인자 넣기\n",
    "    if restore:\n",
    "        encoder_path, decoder_path, discriminator_path = restore\n",
    "        prev_epoch = int(encoder_path.split('-')[0])\n",
    "        En.load_state_dict(torch.load(os.path.join(from_model_path, encoder_path)))\n",
    "        De.load_state_dict(torch.load(os.path.join(from_model_path, decoder_path)))\n",
    "        D.load_state_dict(torch.load(os.path.join(from_model_path, discriminator_path)))\n",
    "        print(\"%d epoch trained model has restored\" % prev_epoch)\n",
    "    else:\n",
    "        prev_epoch = 0\n",
    "        print(\"New model training start\")\n",
    "\n",
    "        \n",
    "    # L1 loss, binary real/fake loss, category loss, constant loss\n",
    "    if GPU:\n",
    "        l1_criterion = nn.L1Loss(size_average=True).cuda()\n",
    "        bce_criterion = nn.BCEWithLogitsLoss(size_average=True).cuda()\n",
    "        mse_criterion = nn.MSELoss(size_average=True).cuda()\n",
    "    else:\n",
    "        l1_criterion = nn.L1Loss(size_average=True)\n",
    "        bce_criterion = nn.BCEWithLogitsLoss(size_average=True)\n",
    "        mse_criterion = nn.MSELoss(size_average=True)\n",
    "\n",
    "\n",
    "    # optimizer\n",
    "    G_parameters = list(En.parameters()) + list(De.parameters())\n",
    "    g_optimizer = torch.optim.Adam(G_parameters, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), betas=(0.5, 0.999))\n",
    "    \n",
    "    # losses lists\n",
    "    l1_losses, const_losses, category_losses, d_losses, g_losses = list(), list(), list(), list(), list()\n",
    "    \n",
    "    # training\n",
    "    count = 0\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch + 1) % schedule == 0:\n",
    "            updated_lr = max(lr/2, 0.0002)\n",
    "            for param_group in d_optimizer.param_groups:\n",
    "                param_group['lr'] = updated_lr\n",
    "            for param_group in g_optimizer.param_groups:\n",
    "                param_group['lr'] = updated_lr\n",
    "            if lr !=  updated_lr:\n",
    "                print(\"decay learning rate from %.5f to %.5f\" % (lr, updated_lr))\n",
    "            lr = updated_lr\n",
    "            \n",
    "        train_batch_iter = data_provider.get_train_iter(BATCH_SIZE)   \n",
    "        for i, batch in enumerate(train_batch_iter):\n",
    "            labels, batch_images = batch\n",
    "            embedding_ids = labels\n",
    "            if GPU:\n",
    "                batch_images = batch_images.cuda()\n",
    "            if flip_labels:\n",
    "                np.random.shuffle(embedding_ids)\n",
    "                \n",
    "            # target / source images\n",
    "            real_target = batch_images[:, 0, :, :].view([BATCH_SIZE, 1, IMG_SIZE, IMG_SIZE])\n",
    "            real_source = batch_images[:, 1, :, :].view([BATCH_SIZE, 1, IMG_SIZE, IMG_SIZE])\n",
    "            \n",
    "            # generate fake image form source image\n",
    "            fake_target, encoded_source = Generator(real_source, En, De, embeddings, embedding_ids, GPU=GPU)\n",
    "            \n",
    "            real_TS = torch.cat([real_source, real_target], dim=1)\n",
    "            fake_TS = torch.cat([real_source, fake_target], dim=1)\n",
    "            \n",
    "            # Scoring with Discriminator\n",
    "            real_score, real_score_logit, real_cat_logit = D(real_TS)\n",
    "            fake_score, fake_score_logit, fake_cat_logit = D(fake_TS)\n",
    "            \n",
    "            # Get encoded fake image to calculate constant loss\n",
    "            encoded_fake = En(fake_target)[0]\n",
    "            const_loss = Lconst_penalty * mse_criterion(encoded_source, encoded_fake)\n",
    "            \n",
    "            # category loss\n",
    "            real_category = torch.from_numpy(np.eye(FONTS_NUM)[embedding_ids]).float()\n",
    "            if GPU:\n",
    "                real_category = real_category.cuda()\n",
    "            real_category_loss = bce_criterion(real_cat_logit, real_category)\n",
    "            fake_category_loss = bce_criterion(fake_cat_logit, real_category)\n",
    "            category_loss = 0.5 * (real_category_loss + fake_category_loss)\n",
    "            \n",
    "            # labels\n",
    "            if GPU:\n",
    "                one_labels = torch.ones([BATCH_SIZE, 1]).cuda()\n",
    "                zero_labels = torch.zeros([BATCH_SIZE, 1]).cuda()\n",
    "            else:\n",
    "                one_labels = torch.ones([BATCH_SIZE, 1])\n",
    "                zero_labels = torch.zeros([BATCH_SIZE, 1])\n",
    "            \n",
    "            # binary loss - T/F\n",
    "            real_binary_loss = bce_criterion(real_score_logit, one_labels)\n",
    "            fake_binary_loss = bce_criterion(fake_score_logit, zero_labels)\n",
    "            binary_loss = real_binary_loss + fake_binary_loss\n",
    "            \n",
    "            # L1 loss between real and fake images\n",
    "            l1_loss = L1_penalty * l1_criterion(real_target, fake_target)\n",
    "            \n",
    "            # cheat loss for generator to fool discriminator\n",
    "            cheat_loss = bce_criterion(fake_score_logit, one_labels)\n",
    "            \n",
    "            # g_loss, d_loss\n",
    "            g_loss = cheat_loss + l1_loss + fake_category_loss + const_loss\n",
    "            d_loss = binary_loss + category_loss\n",
    "            \n",
    "            # train Discriminator\n",
    "            D.zero_grad()\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # train Generator\n",
    "            En.zero_grad()\n",
    "            De.zero_grad()\n",
    "            g_loss.backward(retain_graph=True)\n",
    "            g_optimizer.step()            \n",
    "            \n",
    "            # loss data\n",
    "            l1_losses.append(l1_loss.data)\n",
    "            const_losses.append(const_loss.data)\n",
    "            category_losses.append(category_loss.data)\n",
    "            d_losses.append(d_loss.data)\n",
    "            g_losses.append(g_loss.data)\n",
    "            \n",
    "            # logging\n",
    "            if (i+1) % log_step == 0:\n",
    "                time_ = time.time()\n",
    "                time_stamp = datetime.datetime.fromtimestamp(time_).strftime('%H:%M:%S')\n",
    "                log_format = 'Epoch [%d/%d], step [%d/%d], l1_loss: %.4f, d_loss: %.4f, g_loss: %.4f' % \\\n",
    "                             (int(prev_epoch)+epoch+1, int(prev_epoch)+max_epoch, i+1, total_batches, \\\n",
    "                              l1_loss.item(), d_loss.item(), g_loss.item())\n",
    "                print(time_stamp, log_format)\n",
    "                \n",
    "            # save image\n",
    "            if (i+1) % sample_step == 0:\n",
    "                fixed_fake_images = Generator(fixed_source, En, De, embeddings, fixed_label, GPU=GPU)[0]\n",
    "                save_image(denorm_image(fixed_fake_images.data), \\\n",
    "                           os.path.join(save_path, 'fake_samples-%d-%d.png' % (int(prev_epoch)+epoch+1, i+1)), \\\n",
    "                           nrow=8)\n",
    "        \n",
    "        if (epoch+1) % 5 == 0:\n",
    "            now = datetime.datetime.now()\n",
    "            now_date = now.strftime(\"%m%d\")\n",
    "            now_time = now.strftime('%H:%M')\n",
    "            torch.save(En.state_dict(), os.path.join(to_model_path, '%d-%s-%s-Encoder.pkl' \\\n",
    "                                                     % (int(prev_epoch)+epoch+1, now_date, now_time)))\n",
    "            torch.save(De.state_dict(), os.path.join(to_model_path, '%d-%s-%s-Decoder.pkl' % \\\n",
    "                                                     (int(prev_epoch)+epoch+1, now_date, now_time)))\n",
    "            torch.save(D.state_dict(), os.path.join(to_model_path, '%d-%s-%s-Discriminator.pkl' % \\\n",
    "                                                    (int(prev_epoch)+epoch+1, now_date, now_time)))\n",
    "\n",
    "    # save model\n",
    "    total_epoch = int(prev_epoch) + int(max_epoch)\n",
    "    end = datetime.datetime.now()\n",
    "    end_date = end.strftime(\"%m%d\")\n",
    "    end_time = end.strftime('%H:%M')\n",
    "    torch.save(En.state_dict(), os.path.join(to_model_path, \\\n",
    "                                             '%d-%s-%s-Encoder.pkl' % (total_epoch, end_date, end_time)))\n",
    "    torch.save(De.state_dict(), os.path.join(to_model_path, \\\n",
    "                                             '%d-%s-%s-Decoder.pkl' % (total_epoch, end_date, end_time)))\n",
    "    torch.save(D.state_dict(), os.path.join(to_model_path, \\\n",
    "                                            '%d-%s-%s-Discriminator.pkl' % (total_epoch, end_date, end_time)))\n",
    "    losses = [l1_losses, const_losses, category_losses, d_losses, g_losses]\n",
    "    torch.save(losses, os.path.join(to_model_path, '%d-losses.pkl' % max_epoch))\n",
    "\n",
    "    return l1_losses, const_losses, category_losses, d_losses, g_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lr=0.001` 10epoch / `lr=0.0005` 11~20epoch / `lr=0.00025` 21~30epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New model training start\n",
      "13:45:26 Epoch [1/30], step [500/4672], l1_loss: 31.5673, d_loss: 4.4805, g_loss: 32.0776\n",
      "13:46:58 Epoch [1/30], step [1000/4672], l1_loss: 28.3442, d_loss: 1.5311, g_loss: 32.3137\n",
      "13:48:29 Epoch [1/30], step [1500/4672], l1_loss: 29.9001, d_loss: 1.9606, g_loss: 30.4918\n",
      "13:50:01 Epoch [1/30], step [2000/4672], l1_loss: 23.4462, d_loss: 0.8900, g_loss: 26.2444\n",
      "13:51:32 Epoch [1/30], step [2500/4672], l1_loss: 23.6074, d_loss: 1.4519, g_loss: 24.5044\n",
      "13:53:03 Epoch [1/30], step [3000/4672], l1_loss: 23.3422, d_loss: 0.5449, g_loss: 24.4996\n",
      "13:54:35 Epoch [1/30], step [3500/4672], l1_loss: 23.8832, d_loss: 0.0776, g_loss: 30.3613\n",
      "13:56:06 Epoch [1/30], step [4000/4672], l1_loss: 20.8959, d_loss: 0.1440, g_loss: 27.7757\n",
      "13:57:37 Epoch [1/30], step [4500/4672], l1_loss: 22.4034, d_loss: 0.1014, g_loss: 26.6139\n",
      "13:59:40 Epoch [2/30], step [500/4672], l1_loss: 21.5676, d_loss: 0.4841, g_loss: 23.0573\n",
      "14:01:12 Epoch [2/30], step [1000/4672], l1_loss: 25.3525, d_loss: 0.0555, g_loss: 31.3422\n",
      "14:02:43 Epoch [2/30], step [1500/4672], l1_loss: 22.5974, d_loss: 0.2525, g_loss: 28.6247\n",
      "14:04:14 Epoch [2/30], step [2000/4672], l1_loss: 21.1992, d_loss: 0.0771, g_loss: 27.7436\n",
      "14:05:45 Epoch [2/30], step [2500/4672], l1_loss: 19.6986, d_loss: 0.3519, g_loss: 27.6298\n",
      "14:07:17 Epoch [2/30], step [3000/4672], l1_loss: 20.4004, d_loss: 0.0694, g_loss: 28.1061\n",
      "14:08:48 Epoch [2/30], step [3500/4672], l1_loss: 19.0430, d_loss: 0.1337, g_loss: 23.2905\n",
      "14:10:19 Epoch [2/30], step [4000/4672], l1_loss: 21.8829, d_loss: 0.0886, g_loss: 27.1469\n",
      "14:11:51 Epoch [2/30], step [4500/4672], l1_loss: 17.6297, d_loss: 0.1132, g_loss: 24.1314\n",
      "14:13:53 Epoch [3/30], step [500/4672], l1_loss: 18.1512, d_loss: 0.0730, g_loss: 23.0240\n",
      "14:15:25 Epoch [3/30], step [1000/4672], l1_loss: 20.0472, d_loss: 0.4155, g_loss: 21.9691\n",
      "14:16:56 Epoch [3/30], step [1500/4672], l1_loss: 18.8340, d_loss: 1.8140, g_loss: 19.2463\n",
      "14:18:27 Epoch [3/30], step [2000/4672], l1_loss: 22.3864, d_loss: 0.0552, g_loss: 29.3034\n",
      "14:19:59 Epoch [3/30], step [2500/4672], l1_loss: 17.8266, d_loss: 0.1455, g_loss: 21.3101\n",
      "14:21:30 Epoch [3/30], step [3000/4672], l1_loss: 20.7870, d_loss: 0.0571, g_loss: 26.3819\n",
      "14:23:01 Epoch [3/30], step [3500/4672], l1_loss: 19.7280, d_loss: 0.0493, g_loss: 24.4653\n",
      "14:24:33 Epoch [3/30], step [4000/4672], l1_loss: 19.1936, d_loss: 0.3250, g_loss: 24.1815\n",
      "14:26:04 Epoch [3/30], step [4500/4672], l1_loss: 17.4401, d_loss: 0.1105, g_loss: 23.4361\n",
      "14:28:07 Epoch [4/30], step [500/4672], l1_loss: 20.2373, d_loss: 0.0540, g_loss: 26.2334\n",
      "14:29:38 Epoch [4/30], step [1000/4672], l1_loss: 19.8620, d_loss: 13.1644, g_loss: 19.9635\n",
      "14:31:10 Epoch [4/30], step [1500/4672], l1_loss: 19.1606, d_loss: 0.0813, g_loss: 26.4395\n",
      "14:32:41 Epoch [4/30], step [2000/4672], l1_loss: 18.0314, d_loss: 0.5593, g_loss: 19.3920\n",
      "14:34:13 Epoch [4/30], step [2500/4672], l1_loss: 20.2940, d_loss: 0.0522, g_loss: 27.4286\n",
      "14:35:44 Epoch [4/30], step [3000/4672], l1_loss: 20.9832, d_loss: 0.0345, g_loss: 29.1099\n",
      "14:37:16 Epoch [4/30], step [3500/4672], l1_loss: 20.2340, d_loss: 0.0830, g_loss: 27.1109\n",
      "14:38:47 Epoch [4/30], step [4000/4672], l1_loss: 19.0929, d_loss: 0.0438, g_loss: 28.1050\n",
      "14:40:18 Epoch [4/30], step [4500/4672], l1_loss: 18.7636, d_loss: 0.1345, g_loss: 24.9072\n",
      "14:42:21 Epoch [5/30], step [500/4672], l1_loss: 19.0387, d_loss: 0.0281, g_loss: 25.5375\n",
      "14:43:52 Epoch [5/30], step [1000/4672], l1_loss: 19.2134, d_loss: 0.2143, g_loss: 25.7671\n",
      "14:45:23 Epoch [5/30], step [1500/4672], l1_loss: 22.1701, d_loss: 0.7009, g_loss: 23.7553\n",
      "14:46:54 Epoch [5/30], step [2000/4672], l1_loss: 21.0546, d_loss: 0.0258, g_loss: 26.9963\n",
      "14:48:26 Epoch [5/30], step [2500/4672], l1_loss: 21.4618, d_loss: 0.0655, g_loss: 25.2082\n",
      "14:49:57 Epoch [5/30], step [3000/4672], l1_loss: 19.0736, d_loss: 0.0327, g_loss: 25.7353\n",
      "14:51:28 Epoch [5/30], step [3500/4672], l1_loss: 19.9824, d_loss: 0.0489, g_loss: 28.0450\n",
      "14:53:00 Epoch [5/30], step [4000/4672], l1_loss: 19.1014, d_loss: 0.2049, g_loss: 24.9102\n",
      "14:54:31 Epoch [5/30], step [4500/4672], l1_loss: 22.1297, d_loss: 0.0267, g_loss: 28.2178\n",
      "14:56:34 Epoch [6/30], step [500/4672], l1_loss: 17.5186, d_loss: 0.0316, g_loss: 23.4676\n",
      "14:58:05 Epoch [6/30], step [1000/4672], l1_loss: 21.6442, d_loss: 0.0635, g_loss: 27.4332\n",
      "14:59:36 Epoch [6/30], step [1500/4672], l1_loss: 20.4212, d_loss: 0.0366, g_loss: 26.9267\n",
      "15:01:08 Epoch [6/30], step [2000/4672], l1_loss: 21.0792, d_loss: 0.0401, g_loss: 30.3654\n",
      "15:02:39 Epoch [6/30], step [2500/4672], l1_loss: 17.2006, d_loss: 0.0865, g_loss: 22.2461\n",
      "15:04:10 Epoch [6/30], step [3000/4672], l1_loss: 21.8135, d_loss: 0.0186, g_loss: 27.8899\n",
      "15:05:42 Epoch [6/30], step [3500/4672], l1_loss: 21.0041, d_loss: 0.0209, g_loss: 25.9998\n",
      "15:07:13 Epoch [6/30], step [4000/4672], l1_loss: 20.7170, d_loss: 0.0789, g_loss: 26.6220\n",
      "15:08:44 Epoch [6/30], step [4500/4672], l1_loss: 18.0693, d_loss: 0.0547, g_loss: 25.0073\n",
      "15:10:47 Epoch [7/30], step [500/4672], l1_loss: 20.0570, d_loss: 0.0320, g_loss: 26.5032\n",
      "15:12:18 Epoch [7/30], step [1000/4672], l1_loss: 17.1200, d_loss: 1.6509, g_loss: 24.7070\n",
      "15:13:49 Epoch [7/30], step [1500/4672], l1_loss: 19.0246, d_loss: 0.0598, g_loss: 27.1303\n",
      "15:15:21 Epoch [7/30], step [2000/4672], l1_loss: 17.1620, d_loss: 0.0299, g_loss: 24.0181\n",
      "15:16:52 Epoch [7/30], step [2500/4672], l1_loss: 18.0892, d_loss: 0.0198, g_loss: 24.6175\n",
      "15:18:23 Epoch [7/30], step [3000/4672], l1_loss: 22.2033, d_loss: 0.0465, g_loss: 28.4658\n",
      "15:19:55 Epoch [7/30], step [3500/4672], l1_loss: 21.2127, d_loss: 0.0421, g_loss: 29.8169\n",
      "15:21:26 Epoch [7/30], step [4000/4672], l1_loss: 18.7329, d_loss: 0.0523, g_loss: 26.2843\n",
      "15:22:58 Epoch [7/30], step [4500/4672], l1_loss: 18.8404, d_loss: 0.0385, g_loss: 24.9708\n",
      "15:25:01 Epoch [8/30], step [500/4672], l1_loss: 16.3688, d_loss: 0.0513, g_loss: 22.9294\n",
      "15:26:32 Epoch [8/30], step [1000/4672], l1_loss: 16.6685, d_loss: 0.0403, g_loss: 22.0996\n",
      "15:28:04 Epoch [8/30], step [1500/4672], l1_loss: 19.2377, d_loss: 0.4498, g_loss: 21.1836\n",
      "15:29:35 Epoch [8/30], step [2000/4672], l1_loss: 21.3102, d_loss: 0.3694, g_loss: 30.3759\n",
      "15:31:07 Epoch [8/30], step [2500/4672], l1_loss: 19.9212, d_loss: 0.0772, g_loss: 25.8617\n",
      "15:32:38 Epoch [8/30], step [3000/4672], l1_loss: 20.2079, d_loss: 0.0386, g_loss: 26.6057\n",
      "15:34:09 Epoch [8/30], step [3500/4672], l1_loss: 20.1437, d_loss: 0.0525, g_loss: 28.3740\n",
      "15:35:40 Epoch [8/30], step [4000/4672], l1_loss: 18.7718, d_loss: 0.9021, g_loss: 21.0324\n",
      "15:37:12 Epoch [8/30], step [4500/4672], l1_loss: 21.7765, d_loss: 0.1437, g_loss: 29.9704\n",
      "15:39:14 Epoch [9/30], step [500/4672], l1_loss: 22.9239, d_loss: 0.0442, g_loss: 33.4269\n",
      "15:40:46 Epoch [9/30], step [1000/4672], l1_loss: 21.0525, d_loss: 0.0164, g_loss: 27.2217\n",
      "15:42:17 Epoch [9/30], step [1500/4672], l1_loss: 21.4653, d_loss: 0.0983, g_loss: 28.5418\n",
      "15:43:48 Epoch [9/30], step [2000/4672], l1_loss: 21.4394, d_loss: 0.1105, g_loss: 25.0802\n",
      "15:45:20 Epoch [9/30], step [2500/4672], l1_loss: 24.0582, d_loss: 0.0275, g_loss: 30.0377\n",
      "15:46:51 Epoch [9/30], step [3000/4672], l1_loss: 19.0793, d_loss: 1.1438, g_loss: 22.6973\n",
      "15:48:22 Epoch [9/30], step [3500/4672], l1_loss: 23.0759, d_loss: 0.0645, g_loss: 31.3407\n",
      "15:49:54 Epoch [9/30], step [4000/4672], l1_loss: 18.4920, d_loss: 0.3457, g_loss: 25.5918\n",
      "15:51:25 Epoch [9/30], step [4500/4672], l1_loss: 18.4662, d_loss: 0.5498, g_loss: 26.4857\n",
      "decay learning rate from 0.00100 to 0.00050\n",
      "15:53:28 Epoch [10/30], step [500/4672], l1_loss: 20.8373, d_loss: 0.0168, g_loss: 29.3709\n",
      "15:54:59 Epoch [10/30], step [1000/4672], l1_loss: 19.3256, d_loss: 0.0380, g_loss: 26.6840\n",
      "15:56:30 Epoch [10/30], step [1500/4672], l1_loss: 20.3106, d_loss: 0.0068, g_loss: 26.4936\n",
      "15:58:02 Epoch [10/30], step [2000/4672], l1_loss: 18.3666, d_loss: 0.0088, g_loss: 25.3345\n",
      "15:59:33 Epoch [10/30], step [2500/4672], l1_loss: 19.6075, d_loss: 0.1715, g_loss: 22.1701\n",
      "16:01:04 Epoch [10/30], step [3000/4672], l1_loss: 17.9631, d_loss: 0.0456, g_loss: 27.6605\n",
      "16:02:36 Epoch [10/30], step [3500/4672], l1_loss: 18.2002, d_loss: 0.0096, g_loss: 24.2728\n",
      "16:04:07 Epoch [10/30], step [4000/4672], l1_loss: 17.5954, d_loss: 0.0219, g_loss: 24.5583\n",
      "16:05:39 Epoch [10/30], step [4500/4672], l1_loss: 20.1154, d_loss: 0.0194, g_loss: 25.7591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:07:42 Epoch [11/30], step [500/4672], l1_loss: 17.3532, d_loss: 0.0487, g_loss: 27.4139\n",
      "16:09:13 Epoch [11/30], step [1000/4672], l1_loss: 19.7015, d_loss: 0.0243, g_loss: 28.5345\n",
      "16:10:44 Epoch [11/30], step [1500/4672], l1_loss: 19.1452, d_loss: 0.0408, g_loss: 27.5213\n",
      "16:12:16 Epoch [11/30], step [2000/4672], l1_loss: 16.7137, d_loss: 0.0701, g_loss: 23.5110\n",
      "16:13:47 Epoch [11/30], step [2500/4672], l1_loss: 16.5727, d_loss: 0.0195, g_loss: 24.1229\n",
      "16:15:19 Epoch [11/30], step [3000/4672], l1_loss: 16.8894, d_loss: 0.0256, g_loss: 24.2029\n",
      "16:16:50 Epoch [11/30], step [3500/4672], l1_loss: 17.1674, d_loss: 0.0146, g_loss: 24.1146\n",
      "16:18:22 Epoch [11/30], step [4000/4672], l1_loss: 18.0021, d_loss: 0.0129, g_loss: 25.1344\n",
      "16:19:53 Epoch [11/30], step [4500/4672], l1_loss: 18.8507, d_loss: 0.0727, g_loss: 23.4336\n",
      "16:21:56 Epoch [12/30], step [500/4672], l1_loss: 16.8270, d_loss: 0.0578, g_loss: 24.6033\n",
      "16:23:28 Epoch [12/30], step [1000/4672], l1_loss: 19.2569, d_loss: 0.0154, g_loss: 24.3346\n",
      "16:24:59 Epoch [12/30], step [1500/4672], l1_loss: 20.3671, d_loss: 0.0108, g_loss: 29.3073\n",
      "16:26:31 Epoch [12/30], step [2000/4672], l1_loss: 18.8449, d_loss: 0.0211, g_loss: 26.9713\n",
      "16:28:03 Epoch [12/30], step [2500/4672], l1_loss: 16.8186, d_loss: 0.0192, g_loss: 26.1608\n",
      "16:29:34 Epoch [12/30], step [3000/4672], l1_loss: 18.1441, d_loss: 0.0943, g_loss: 25.9603\n",
      "16:31:06 Epoch [12/30], step [3500/4672], l1_loss: 19.2469, d_loss: 0.0115, g_loss: 28.4802\n",
      "16:32:37 Epoch [12/30], step [4000/4672], l1_loss: 18.6048, d_loss: 0.0263, g_loss: 23.9313\n",
      "16:34:09 Epoch [12/30], step [4500/4672], l1_loss: 19.8209, d_loss: 0.0356, g_loss: 30.6763\n",
      "16:36:11 Epoch [13/30], step [500/4672], l1_loss: 21.3068, d_loss: 0.0345, g_loss: 30.2617\n",
      "16:37:43 Epoch [13/30], step [1000/4672], l1_loss: 18.7451, d_loss: 0.0131, g_loss: 26.4190\n",
      "16:39:15 Epoch [13/30], step [1500/4672], l1_loss: 18.2333, d_loss: 0.0083, g_loss: 26.9985\n",
      "16:40:46 Epoch [13/30], step [2000/4672], l1_loss: 17.5595, d_loss: 0.0153, g_loss: 24.5925\n",
      "16:42:18 Epoch [13/30], step [2500/4672], l1_loss: 17.2354, d_loss: 0.3776, g_loss: 25.3360\n",
      "16:43:49 Epoch [13/30], step [3000/4672], l1_loss: 17.4736, d_loss: 0.0180, g_loss: 25.9648\n",
      "16:45:21 Epoch [13/30], step [3500/4672], l1_loss: 22.9028, d_loss: 0.0267, g_loss: 34.3324\n",
      "16:46:53 Epoch [13/30], step [4000/4672], l1_loss: 18.3975, d_loss: 0.0274, g_loss: 28.8694\n",
      "16:48:25 Epoch [13/30], step [4500/4672], l1_loss: 18.7655, d_loss: 0.0187, g_loss: 24.8300\n",
      "16:50:28 Epoch [14/30], step [500/4672], l1_loss: 19.6992, d_loss: 0.0288, g_loss: 26.8870\n",
      "16:51:59 Epoch [14/30], step [1000/4672], l1_loss: 19.9129, d_loss: 0.0287, g_loss: 28.6221\n",
      "16:53:31 Epoch [14/30], step [1500/4672], l1_loss: 19.2532, d_loss: 0.0235, g_loss: 25.6737\n",
      "16:55:03 Epoch [14/30], step [2000/4672], l1_loss: 17.3130, d_loss: 0.0271, g_loss: 23.9762\n",
      "16:56:34 Epoch [14/30], step [2500/4672], l1_loss: 15.4800, d_loss: 0.8638, g_loss: 16.3274\n",
      "16:58:05 Epoch [14/30], step [3000/4672], l1_loss: 17.9598, d_loss: 0.0147, g_loss: 25.9638\n",
      "16:59:37 Epoch [14/30], step [3500/4672], l1_loss: 19.0962, d_loss: 0.0407, g_loss: 30.6646\n",
      "17:01:09 Epoch [14/30], step [4000/4672], l1_loss: 22.5323, d_loss: 0.0214, g_loss: 28.6565\n",
      "17:02:40 Epoch [14/30], step [4500/4672], l1_loss: 17.3399, d_loss: 0.0220, g_loss: 27.3030\n",
      "17:04:44 Epoch [15/30], step [500/4672], l1_loss: 15.5659, d_loss: 0.0347, g_loss: 21.9881\n",
      "17:06:15 Epoch [15/30], step [1000/4672], l1_loss: 16.3408, d_loss: 0.0150, g_loss: 23.8493\n",
      "17:07:47 Epoch [15/30], step [1500/4672], l1_loss: 19.5778, d_loss: 0.0172, g_loss: 27.0347\n",
      "17:09:18 Epoch [15/30], step [2000/4672], l1_loss: 17.2751, d_loss: 0.0074, g_loss: 25.2176\n",
      "17:10:50 Epoch [15/30], step [2500/4672], l1_loss: 15.8518, d_loss: 0.0254, g_loss: 23.1232\n",
      "17:12:22 Epoch [15/30], step [3000/4672], l1_loss: 18.2221, d_loss: 0.0276, g_loss: 22.6383\n",
      "17:13:53 Epoch [15/30], step [3500/4672], l1_loss: 16.6865, d_loss: 0.0117, g_loss: 22.8770\n",
      "17:15:25 Epoch [15/30], step [4000/4672], l1_loss: 21.4265, d_loss: 0.0554, g_loss: 26.7053\n",
      "17:16:57 Epoch [15/30], step [4500/4672], l1_loss: 18.8371, d_loss: 0.0180, g_loss: 27.5874\n",
      "17:19:00 Epoch [16/30], step [500/4672], l1_loss: 18.1289, d_loss: 0.0393, g_loss: 27.5202\n",
      "17:20:32 Epoch [16/30], step [1000/4672], l1_loss: 19.5396, d_loss: 0.0251, g_loss: 28.0651\n",
      "17:22:03 Epoch [16/30], step [1500/4672], l1_loss: 22.0123, d_loss: 0.0155, g_loss: 30.1424\n",
      "17:23:35 Epoch [16/30], step [2000/4672], l1_loss: 19.7690, d_loss: 0.0189, g_loss: 29.5909\n",
      "17:25:07 Epoch [16/30], step [2500/4672], l1_loss: 18.0812, d_loss: 0.0177, g_loss: 23.5812\n",
      "17:26:38 Epoch [16/30], step [3000/4672], l1_loss: 19.2301, d_loss: 0.0338, g_loss: 24.9967\n",
      "17:28:10 Epoch [16/30], step [3500/4672], l1_loss: 17.1486, d_loss: 0.0125, g_loss: 23.4845\n",
      "17:29:41 Epoch [16/30], step [4000/4672], l1_loss: 17.3544, d_loss: 0.0199, g_loss: 25.2219\n",
      "17:31:13 Epoch [16/30], step [4500/4672], l1_loss: 16.0856, d_loss: 0.0253, g_loss: 23.8974\n",
      "17:33:16 Epoch [17/30], step [500/4672], l1_loss: 18.5930, d_loss: 0.0712, g_loss: 27.9124\n",
      "17:34:47 Epoch [17/30], step [1000/4672], l1_loss: 18.7411, d_loss: 0.0177, g_loss: 29.4386\n",
      "17:36:19 Epoch [17/30], step [1500/4672], l1_loss: 17.1120, d_loss: 0.0068, g_loss: 24.5784\n",
      "17:37:51 Epoch [17/30], step [2000/4672], l1_loss: 18.7856, d_loss: 0.0108, g_loss: 29.1811\n",
      "17:39:22 Epoch [17/30], step [2500/4672], l1_loss: 21.2872, d_loss: 0.0142, g_loss: 28.3504\n",
      "17:40:54 Epoch [17/30], step [3000/4672], l1_loss: 18.8717, d_loss: 5.7496, g_loss: 18.8914\n",
      "17:42:26 Epoch [17/30], step [3500/4672], l1_loss: 19.4253, d_loss: 0.0144, g_loss: 30.7498\n",
      "17:43:58 Epoch [17/30], step [4000/4672], l1_loss: 17.8905, d_loss: 0.0142, g_loss: 26.1274\n",
      "17:45:29 Epoch [17/30], step [4500/4672], l1_loss: 17.0592, d_loss: 0.0189, g_loss: 25.5811\n",
      "17:47:32 Epoch [18/30], step [500/4672], l1_loss: 15.6805, d_loss: 0.0184, g_loss: 21.4519\n",
      "17:49:04 Epoch [18/30], step [1000/4672], l1_loss: 17.2406, d_loss: 0.0074, g_loss: 25.7827\n",
      "17:50:35 Epoch [18/30], step [1500/4672], l1_loss: 16.3088, d_loss: 0.0170, g_loss: 25.5297\n",
      "17:52:07 Epoch [18/30], step [2000/4672], l1_loss: 18.3492, d_loss: 0.0152, g_loss: 28.5314\n",
      "17:53:39 Epoch [18/30], step [2500/4672], l1_loss: 18.3370, d_loss: 0.0208, g_loss: 25.1195\n",
      "17:55:10 Epoch [18/30], step [3000/4672], l1_loss: 18.1420, d_loss: 0.0221, g_loss: 28.1542\n",
      "17:56:42 Epoch [18/30], step [3500/4672], l1_loss: 18.9539, d_loss: 0.0191, g_loss: 28.7405\n",
      "17:58:13 Epoch [18/30], step [4000/4672], l1_loss: 18.4373, d_loss: 0.0231, g_loss: 31.0233\n",
      "17:59:45 Epoch [18/30], step [4500/4672], l1_loss: 17.5327, d_loss: 0.0153, g_loss: 24.4903\n",
      "18:01:48 Epoch [19/30], step [500/4672], l1_loss: 18.4257, d_loss: 0.1427, g_loss: 26.8282\n",
      "18:03:20 Epoch [19/30], step [1000/4672], l1_loss: 19.5150, d_loss: 0.0172, g_loss: 27.4203\n",
      "18:04:51 Epoch [19/30], step [1500/4672], l1_loss: 19.8208, d_loss: 0.0069, g_loss: 29.8569\n",
      "18:06:23 Epoch [19/30], step [2000/4672], l1_loss: 16.6541, d_loss: 0.0175, g_loss: 22.4365\n",
      "18:07:54 Epoch [19/30], step [2500/4672], l1_loss: 17.5015, d_loss: 0.0276, g_loss: 22.6935\n",
      "18:09:26 Epoch [19/30], step [3000/4672], l1_loss: 20.1047, d_loss: 0.0172, g_loss: 29.5590\n",
      "18:10:58 Epoch [19/30], step [3500/4672], l1_loss: 16.1457, d_loss: 0.0114, g_loss: 25.1953\n",
      "18:12:29 Epoch [19/30], step [4000/4672], l1_loss: 20.8573, d_loss: 0.0102, g_loss: 30.4625\n",
      "18:14:01 Epoch [19/30], step [4500/4672], l1_loss: 18.6808, d_loss: 0.0247, g_loss: 26.7106\n",
      "decay learning rate from 0.00050 to 0.00025\n",
      "18:16:04 Epoch [20/30], step [500/4672], l1_loss: 16.2876, d_loss: 0.0174, g_loss: 22.6024\n",
      "18:17:36 Epoch [20/30], step [1000/4672], l1_loss: 18.7980, d_loss: 0.0880, g_loss: 23.0287\n",
      "18:19:08 Epoch [20/30], step [1500/4672], l1_loss: 19.5848, d_loss: 0.0174, g_loss: 25.8553\n",
      "18:20:39 Epoch [20/30], step [2000/4672], l1_loss: 16.7091, d_loss: 0.0036, g_loss: 25.5583\n",
      "18:22:11 Epoch [20/30], step [2500/4672], l1_loss: 16.2410, d_loss: 0.0418, g_loss: 20.7080\n",
      "18:23:42 Epoch [20/30], step [3000/4672], l1_loss: 18.7394, d_loss: 0.0119, g_loss: 26.4422\n",
      "18:25:14 Epoch [20/30], step [3500/4672], l1_loss: 18.2053, d_loss: 0.0118, g_loss: 29.8635\n",
      "18:26:45 Epoch [20/30], step [4000/4672], l1_loss: 17.5193, d_loss: 0.0079, g_loss: 24.1277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18:28:17 Epoch [20/30], step [4500/4672], l1_loss: 15.4743, d_loss: 0.0193, g_loss: 26.0741\n",
      "18:30:20 Epoch [21/30], step [500/4672], l1_loss: 17.8909, d_loss: 0.0137, g_loss: 26.6243\n",
      "18:31:52 Epoch [21/30], step [1000/4672], l1_loss: 17.7067, d_loss: 0.1211, g_loss: 20.6086\n",
      "18:33:24 Epoch [21/30], step [1500/4672], l1_loss: 19.2615, d_loss: 0.0169, g_loss: 28.4378\n",
      "18:34:55 Epoch [21/30], step [2000/4672], l1_loss: 18.0181, d_loss: 0.0195, g_loss: 24.2373\n",
      "18:36:27 Epoch [21/30], step [2500/4672], l1_loss: 18.4976, d_loss: 0.0127, g_loss: 24.6040\n",
      "18:37:58 Epoch [21/30], step [3000/4672], l1_loss: 19.7455, d_loss: 0.0232, g_loss: 28.4466\n",
      "18:39:30 Epoch [21/30], step [3500/4672], l1_loss: 16.4863, d_loss: 0.2534, g_loss: 18.6543\n",
      "18:41:01 Epoch [21/30], step [4000/4672], l1_loss: 16.4772, d_loss: 0.0108, g_loss: 26.4275\n",
      "18:42:33 Epoch [21/30], step [4500/4672], l1_loss: 17.0904, d_loss: 0.0183, g_loss: 25.6196\n",
      "18:44:35 Epoch [22/30], step [500/4672], l1_loss: 15.9008, d_loss: 0.0151, g_loss: 22.7936\n",
      "18:46:07 Epoch [22/30], step [1000/4672], l1_loss: 20.6946, d_loss: 0.0211, g_loss: 26.3547\n",
      "18:47:38 Epoch [22/30], step [1500/4672], l1_loss: 16.1257, d_loss: 0.0174, g_loss: 23.8604\n",
      "18:49:09 Epoch [22/30], step [2000/4672], l1_loss: 20.2798, d_loss: 0.0045, g_loss: 30.9017\n",
      "18:50:41 Epoch [22/30], step [2500/4672], l1_loss: 17.1834, d_loss: 0.0166, g_loss: 26.6944\n",
      "18:52:12 Epoch [22/30], step [3000/4672], l1_loss: 20.1953, d_loss: 0.0201, g_loss: 26.5080\n",
      "18:53:43 Epoch [22/30], step [3500/4672], l1_loss: 20.1532, d_loss: 0.0163, g_loss: 31.1199\n",
      "18:55:15 Epoch [22/30], step [4000/4672], l1_loss: 18.1498, d_loss: 0.0072, g_loss: 28.5048\n",
      "18:56:46 Epoch [22/30], step [4500/4672], l1_loss: 17.5647, d_loss: 0.0169, g_loss: 23.7515\n",
      "18:58:49 Epoch [23/30], step [500/4672], l1_loss: 18.0497, d_loss: 0.0100, g_loss: 27.9038\n",
      "19:00:20 Epoch [23/30], step [1000/4672], l1_loss: 19.5548, d_loss: 0.0285, g_loss: 24.4137\n",
      "19:01:51 Epoch [23/30], step [1500/4672], l1_loss: 16.5592, d_loss: 0.0154, g_loss: 25.8478\n",
      "19:03:23 Epoch [23/30], step [2000/4672], l1_loss: 16.6642, d_loss: 0.0212, g_loss: 22.8592\n",
      "19:04:54 Epoch [23/30], step [2500/4672], l1_loss: 19.4691, d_loss: 0.0313, g_loss: 24.6987\n",
      "19:06:26 Epoch [23/30], step [3000/4672], l1_loss: 17.5164, d_loss: 0.0069, g_loss: 23.9358\n",
      "19:07:58 Epoch [23/30], step [3500/4672], l1_loss: 17.7869, d_loss: 0.0064, g_loss: 23.9878\n",
      "19:09:29 Epoch [23/30], step [4000/4672], l1_loss: 18.9908, d_loss: 0.0066, g_loss: 27.5955\n",
      "19:11:01 Epoch [23/30], step [4500/4672], l1_loss: 15.8173, d_loss: 0.0083, g_loss: 26.0838\n",
      "19:13:03 Epoch [24/30], step [500/4672], l1_loss: 16.6858, d_loss: 0.0969, g_loss: 20.7486\n",
      "19:14:35 Epoch [24/30], step [1000/4672], l1_loss: 18.2227, d_loss: 0.0300, g_loss: 23.3241\n",
      "19:16:06 Epoch [24/30], step [1500/4672], l1_loss: 18.5738, d_loss: 0.0236, g_loss: 23.3758\n",
      "19:17:37 Epoch [24/30], step [2000/4672], l1_loss: 15.7178, d_loss: 0.0111, g_loss: 24.0037\n",
      "19:19:09 Epoch [24/30], step [2500/4672], l1_loss: 16.1264, d_loss: 0.0194, g_loss: 20.9515\n",
      "19:20:40 Epoch [24/30], step [3000/4672], l1_loss: 19.3269, d_loss: 0.0139, g_loss: 26.9400\n",
      "19:22:11 Epoch [24/30], step [3500/4672], l1_loss: 19.9093, d_loss: 0.0048, g_loss: 26.8422\n",
      "19:23:43 Epoch [24/30], step [4000/4672], l1_loss: 16.2752, d_loss: 0.0258, g_loss: 21.0607\n",
      "19:25:14 Epoch [24/30], step [4500/4672], l1_loss: 19.4475, d_loss: 0.0161, g_loss: 25.3240\n",
      "19:27:17 Epoch [25/30], step [500/4672], l1_loss: 18.6714, d_loss: 0.0162, g_loss: 27.2750\n",
      "19:28:48 Epoch [25/30], step [1000/4672], l1_loss: 15.2530, d_loss: 0.0113, g_loss: 22.5822\n",
      "19:30:19 Epoch [25/30], step [1500/4672], l1_loss: 19.1601, d_loss: 0.0177, g_loss: 27.8971\n",
      "19:31:51 Epoch [25/30], step [2000/4672], l1_loss: 17.4244, d_loss: 0.2221, g_loss: 26.6028\n",
      "19:33:22 Epoch [25/30], step [2500/4672], l1_loss: 18.0928, d_loss: 0.0090, g_loss: 26.7359\n",
      "19:34:54 Epoch [25/30], step [3000/4672], l1_loss: 16.1407, d_loss: 0.0339, g_loss: 22.6622\n",
      "19:36:25 Epoch [25/30], step [3500/4672], l1_loss: 18.6284, d_loss: 0.0176, g_loss: 25.7056\n",
      "19:37:57 Epoch [25/30], step [4000/4672], l1_loss: 16.0727, d_loss: 0.0026, g_loss: 23.4073\n",
      "19:39:28 Epoch [25/30], step [4500/4672], l1_loss: 17.4302, d_loss: 0.0065, g_loss: 23.2335\n",
      "19:41:31 Epoch [26/30], step [500/4672], l1_loss: 17.1556, d_loss: 0.0191, g_loss: 23.0532\n",
      "19:43:02 Epoch [26/30], step [1000/4672], l1_loss: 17.3822, d_loss: 0.0122, g_loss: 25.2904\n",
      "19:44:34 Epoch [26/30], step [1500/4672], l1_loss: 18.1173, d_loss: 0.0046, g_loss: 27.0904\n",
      "19:46:05 Epoch [26/30], step [2000/4672], l1_loss: 17.3883, d_loss: 0.0073, g_loss: 26.8261\n",
      "19:47:37 Epoch [26/30], step [2500/4672], l1_loss: 15.6274, d_loss: 0.1321, g_loss: 25.2152\n",
      "19:49:08 Epoch [26/30], step [3000/4672], l1_loss: 16.0620, d_loss: 0.0308, g_loss: 22.4431\n",
      "19:50:40 Epoch [26/30], step [3500/4672], l1_loss: 17.6587, d_loss: 0.0375, g_loss: 25.4644\n",
      "19:52:11 Epoch [26/30], step [4000/4672], l1_loss: 15.4946, d_loss: 0.0043, g_loss: 22.5612\n",
      "19:53:42 Epoch [26/30], step [4500/4672], l1_loss: 19.8125, d_loss: 0.0239, g_loss: 27.8293\n",
      "19:55:45 Epoch [27/30], step [500/4672], l1_loss: 14.6791, d_loss: 0.0211, g_loss: 19.4341\n",
      "19:57:16 Epoch [27/30], step [1000/4672], l1_loss: 17.3621, d_loss: 0.0148, g_loss: 25.9893\n",
      "19:58:48 Epoch [27/30], step [1500/4672], l1_loss: 19.5667, d_loss: 0.0029, g_loss: 27.8432\n",
      "20:00:20 Epoch [27/30], step [2000/4672], l1_loss: 16.7885, d_loss: 0.0206, g_loss: 23.9074\n",
      "20:01:51 Epoch [27/30], step [2500/4672], l1_loss: 15.6396, d_loss: 0.0184, g_loss: 25.2074\n",
      "20:03:23 Epoch [27/30], step [3000/4672], l1_loss: 16.0064, d_loss: 0.0055, g_loss: 23.7231\n",
      "20:04:54 Epoch [27/30], step [3500/4672], l1_loss: 17.5797, d_loss: 0.0109, g_loss: 23.5447\n",
      "20:06:26 Epoch [27/30], step [4000/4672], l1_loss: 17.0402, d_loss: 0.0964, g_loss: 20.6128\n",
      "20:07:57 Epoch [27/30], step [4500/4672], l1_loss: 18.7644, d_loss: 0.0070, g_loss: 27.2935\n",
      "20:10:00 Epoch [28/30], step [500/4672], l1_loss: 16.9300, d_loss: 0.0243, g_loss: 22.3750\n",
      "20:11:32 Epoch [28/30], step [1000/4672], l1_loss: 17.0490, d_loss: 0.0874, g_loss: 25.0916\n",
      "20:13:04 Epoch [28/30], step [1500/4672], l1_loss: 20.3949, d_loss: 0.0174, g_loss: 28.8510\n",
      "20:14:35 Epoch [28/30], step [2000/4672], l1_loss: 15.8822, d_loss: 0.0033, g_loss: 24.3532\n",
      "20:16:07 Epoch [28/30], step [2500/4672], l1_loss: 15.6572, d_loss: 0.0115, g_loss: 20.9171\n",
      "20:17:39 Epoch [28/30], step [3000/4672], l1_loss: 14.8509, d_loss: 0.0941, g_loss: 19.0451\n",
      "20:19:10 Epoch [28/30], step [3500/4672], l1_loss: 15.7364, d_loss: 0.0114, g_loss: 23.4348\n",
      "20:20:42 Epoch [28/30], step [4000/4672], l1_loss: 19.7435, d_loss: 0.0090, g_loss: 25.8058\n",
      "20:22:14 Epoch [28/30], step [4500/4672], l1_loss: 15.6685, d_loss: 0.0066, g_loss: 25.5947\n",
      "20:24:17 Epoch [29/30], step [500/4672], l1_loss: 15.3484, d_loss: 0.2343, g_loss: 24.4842\n",
      "20:25:48 Epoch [29/30], step [1000/4672], l1_loss: 17.9701, d_loss: 0.0145, g_loss: 25.6086\n",
      "20:27:20 Epoch [29/30], step [1500/4672], l1_loss: 17.5603, d_loss: 0.0075, g_loss: 24.8980\n",
      "20:28:52 Epoch [29/30], step [2000/4672], l1_loss: 18.6747, d_loss: 0.0226, g_loss: 24.9635\n",
      "20:30:23 Epoch [29/30], step [2500/4672], l1_loss: 16.8378, d_loss: 0.0201, g_loss: 23.1258\n",
      "20:31:55 Epoch [29/30], step [3000/4672], l1_loss: 18.3534, d_loss: 0.0153, g_loss: 23.6939\n",
      "20:33:26 Epoch [29/30], step [3500/4672], l1_loss: 16.5776, d_loss: 0.0454, g_loss: 20.7569\n",
      "20:34:58 Epoch [29/30], step [4000/4672], l1_loss: 19.0686, d_loss: 0.0240, g_loss: 28.8992\n",
      "20:36:30 Epoch [29/30], step [4500/4672], l1_loss: 17.7256, d_loss: 0.1393, g_loss: 20.2871\n",
      "decay learning rate from 0.00025 to 0.00020\n",
      "20:38:33 Epoch [30/30], step [500/4672], l1_loss: 20.1649, d_loss: 0.0013, g_loss: 30.7635\n",
      "20:40:04 Epoch [30/30], step [1000/4672], l1_loss: 17.3284, d_loss: 0.0309, g_loss: 21.6340\n",
      "20:41:36 Epoch [30/30], step [1500/4672], l1_loss: 22.9669, d_loss: 0.0086, g_loss: 33.9026\n",
      "20:43:08 Epoch [30/30], step [2000/4672], l1_loss: 16.7512, d_loss: 0.7954, g_loss: 31.3152\n",
      "20:44:39 Epoch [30/30], step [2500/4672], l1_loss: 17.5401, d_loss: 0.0081, g_loss: 25.8929\n",
      "20:46:11 Epoch [30/30], step [3000/4672], l1_loss: 15.4077, d_loss: 0.0218, g_loss: 25.3068\n",
      "20:47:43 Epoch [30/30], step [3500/4672], l1_loss: 16.8037, d_loss: 0.0010, g_loss: 25.7484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:49:14 Epoch [30/30], step [4000/4672], l1_loss: 19.1727, d_loss: 0.0100, g_loss: 25.7169\n",
      "20:50:46 Epoch [30/30], step [4500/4672], l1_loss: 19.1303, d_loss: 0.0019, g_loss: 30.1648\n"
     ]
    }
   ],
   "source": [
    "save_path = './fixed_fake/'\n",
    "to_model_path = './model_checkpoint/'\n",
    "losses = train(max_epoch=30, schedule=10, data_dir=data_dir, save_path=save_path, \\\n",
    "               to_model_path=to_model_path, log_step=500, sample_step=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 약 14분/1epoch : 2시간20분/10epoch\n",
    "\n",
    "\n",
    "- 7시간/30epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
